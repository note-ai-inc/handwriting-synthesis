[[05/07/2025 09:56:38 PM]] 
new run with parameters:
{'attention_mixture_components': 10,
 'batch_size': 32,
 'batch_sizes': [32],
 'beta1_decay': 0.9,
 'beta1_decays': [0.9],
 'checkpoint_dir': 'checkpoints_style_synthesis',
 'early_stopping_steps': 2000,
 'enable_parameter_averaging': False,
 'grad_clip': 10,
 'keep_prob_scalar': 1.0,
 'learning_rate': 0.0001,
 'learning_rates': [0.0001],
 'log_dir': 'logs_style_synthesis',
 'log_interval': 50,
 'logging_level': 20,
 'loss_averaging_window': 100,
 'lstm_size': 400,
 'min_steps_to_checkpoint': 2000,
 'num_restarts': 0,
 'num_training_steps': 30000,
 'optimizer': 'rms',
 'output_mixture_components': 20,
 'output_units': 121,
 'patiences': [2000],
 'prediction_dir': 'predictions_style_synthesis',
 'reader': <train.StyleDataReader object at 0x7fc396454128>,
 'regularization_constant': 0.0,
 'restart_idx': 0,
 'style_embedding_size': 256,
 'validation_batch_size': 32,
 'warm_start_init_step': 0}
[[05/07/2025 09:56:40 PM]] all parameters:
[[05/07/2025 09:56:40 PM]] [('Variable:0', []),
 ('Variable_1:0', []),
 ('Variable_2:0', []),
 ('style_encoder/bidirectional/lstm_cell/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias:0', [512]),
 ('style_encoder/dense/kernel:0', [256, 1]),
 ('style_encoder/dense/bias:0', [1]),
 ('style_encoder/dense_1/kernel:0', [256, 256]),
 ('style_encoder/dense_1/bias:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel:0', [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights:0', [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias:0', [1600]),
 ('rnn_style/gmm/weights:0', [400, 121]),
 ('rnn_style/gmm/biases:0', [121]),
 ('style_encoder/bidirectional/lstm_cell/kernel/RMSProp:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/kernel/RMSProp_1:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel/RMSProp:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel/RMSProp_1:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias/RMSProp:0', [512]),
 ('style_encoder/bidirectional/lstm_cell/bias/RMSProp_1:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel/RMSProp:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel/RMSProp_1:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel/RMSProp:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel/RMSProp_1:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias/RMSProp:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias/RMSProp_1:0', [512]),
 ('style_encoder/dense/kernel/RMSProp:0', [256, 1]),
 ('style_encoder/dense/kernel/RMSProp_1:0', [256, 1]),
 ('style_encoder/dense/bias/RMSProp:0', [1]),
 ('style_encoder/dense/bias/RMSProp_1:0', [1]),
 ('style_encoder/dense_1/kernel/RMSProp:0', [256, 256]),
 ('style_encoder/dense_1/kernel/RMSProp_1:0', [256, 256]),
 ('style_encoder/dense_1/bias/RMSProp:0', [256]),
 ('style_encoder/dense_1/bias/RMSProp_1:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel/RMSProp:0',
  [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel/RMSProp_1:0',
  [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias/RMSProp:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights/RMSProp:0',
  [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights/RMSProp_1:0',
  [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases/RMSProp:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases/RMSProp_1:0',
  [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel/RMSProp:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel/RMSProp_1:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias/RMSProp:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel/RMSProp:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel/RMSProp_1:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias/RMSProp:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/gmm/weights/RMSProp:0', [400, 121]),
 ('rnn_style/gmm/weights/RMSProp_1:0', [400, 121]),
 ('rnn_style/gmm/biases/RMSProp:0', [121]),
 ('rnn_style/gmm/biases/RMSProp_1:0', [121])]
[[05/07/2025 09:56:40 PM]] trainable parameters:
[[05/07/2025 09:56:40 PM]] [('style_encoder/bidirectional/lstm_cell/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias:0', [512]),
 ('style_encoder/dense/kernel:0', [256, 1]),
 ('style_encoder/dense/bias:0', [1]),
 ('style_encoder/dense_1/kernel:0', [256, 256]),
 ('style_encoder/dense_1/bias:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel:0', [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights:0', [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias:0', [1600]),
 ('rnn_style/gmm/weights:0', [400, 121]),
 ('rnn_style/gmm/biases:0', [121])]
[[05/07/2025 09:56:40 PM]] trainable parameter count:
[[05/07/2025 09:56:40 PM]] 5070128
[[05/07/2025 09:56:40 PM]] built graph
[[05/07/2025 09:56:40 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:56:40 PM]] Started server process [7]
[[05/07/2025 09:56:40 PM]] Waiting for application startup.
[[05/07/2025 09:56:40 PM]] Application startup complete.
[[05/07/2025 09:56:53 PM]] 
new run with parameters:
{'attention_mixture_components': 10,
 'batch_size': 32,
 'batch_sizes': [32],
 'beta1_decay': 0.9,
 'beta1_decays': [0.9],
 'checkpoint_dir': 'checkpoints_style_synthesis',
 'early_stopping_steps': 2000,
 'enable_parameter_averaging': False,
 'grad_clip': 10,
 'keep_prob_scalar': 1.0,
 'learning_rate': 0.0001,
 'learning_rates': [0.0001],
 'log_dir': 'logs_style_synthesis',
 'log_interval': 50,
 'logging_level': 20,
 'loss_averaging_window': 100,
 'lstm_size': 400,
 'min_steps_to_checkpoint': 2000,
 'num_restarts': 0,
 'num_training_steps': 30000,
 'optimizer': 'rms',
 'output_mixture_components': 20,
 'output_units': 121,
 'patiences': [2000],
 'prediction_dir': 'predictions_style_synthesis',
 'reader': <train.StyleDataReader object at 0x7dfa53092358>,
 'regularization_constant': 0.0,
 'restart_idx': 0,
 'style_embedding_size': 256,
 'validation_batch_size': 32,
 'warm_start_init_step': 0}
[[05/07/2025 09:56:53 PM]] 
new run with parameters:
{'attention_mixture_components': 10,
 'batch_size': 32,
 'batch_sizes': [32],
 'beta1_decay': 0.9,
 'beta1_decays': [0.9],
 'checkpoint_dir': 'checkpoints_style_synthesis',
 'early_stopping_steps': 2000,
 'enable_parameter_averaging': False,
 'grad_clip': 10,
 'keep_prob_scalar': 1.0,
 'learning_rate': 0.0001,
 'learning_rates': [0.0001],
 'log_dir': 'logs_style_synthesis',
 'log_interval': 50,
 'logging_level': 20,
 'loss_averaging_window': 100,
 'lstm_size': 400,
 'min_steps_to_checkpoint': 2000,
 'num_restarts': 0,
 'num_training_steps': 30000,
 'optimizer': 'rms',
 'output_mixture_components': 20,
 'output_units': 121,
 'patiences': [2000],
 'prediction_dir': 'predictions_style_synthesis',
 'reader': <train.StyleDataReader object at 0x71ae93e13358>,
 'regularization_constant': 0.0,
 'restart_idx': 0,
 'style_embedding_size': 256,
 'validation_batch_size': 32,
 'warm_start_init_step': 0}
[[05/07/2025 09:56:53 PM]] 
new run with parameters:
{'attention_mixture_components': 10,
 'batch_size': 32,
 'batch_sizes': [32],
 'beta1_decay': 0.9,
 'beta1_decays': [0.9],
 'checkpoint_dir': 'checkpoints_style_synthesis',
 'early_stopping_steps': 2000,
 'enable_parameter_averaging': False,
 'grad_clip': 10,
 'keep_prob_scalar': 1.0,
 'learning_rate': 0.0001,
 'learning_rates': [0.0001],
 'log_dir': 'logs_style_synthesis',
 'log_interval': 50,
 'logging_level': 20,
 'loss_averaging_window': 100,
 'lstm_size': 400,
 'min_steps_to_checkpoint': 2000,
 'num_restarts': 0,
 'num_training_steps': 30000,
 'optimizer': 'rms',
 'output_mixture_components': 20,
 'output_units': 121,
 'patiences': [2000],
 'prediction_dir': 'predictions_style_synthesis',
 'reader': <train.StyleDataReader object at 0x7fde16edc358>,
 'regularization_constant': 0.0,
 'restart_idx': 0,
 'style_embedding_size': 256,
 'validation_batch_size': 32,
 'warm_start_init_step': 0}
[[05/07/2025 09:56:53 PM]] 
new run with parameters:
{'attention_mixture_components': 10,
 'batch_size': 32,
 'batch_sizes': [32],
 'beta1_decay': 0.9,
 'beta1_decays': [0.9],
 'checkpoint_dir': 'checkpoints_style_synthesis',
 'early_stopping_steps': 2000,
 'enable_parameter_averaging': False,
 'grad_clip': 10,
 'keep_prob_scalar': 1.0,
 'learning_rate': 0.0001,
 'learning_rates': [0.0001],
 'log_dir': 'logs_style_synthesis',
 'log_interval': 50,
 'logging_level': 20,
 'loss_averaging_window': 100,
 'lstm_size': 400,
 'min_steps_to_checkpoint': 2000,
 'num_restarts': 0,
 'num_training_steps': 30000,
 'optimizer': 'rms',
 'output_mixture_components': 20,
 'output_units': 121,
 'patiences': [2000],
 'prediction_dir': 'predictions_style_synthesis',
 'reader': <train.StyleDataReader object at 0x7e6e7d62f2e8>,
 'regularization_constant': 0.0,
 'restart_idx': 0,
 'style_embedding_size': 256,
 'validation_batch_size': 32,
 'warm_start_init_step': 0}
[[05/07/2025 09:56:59 PM]] all parameters:
[[05/07/2025 09:56:59 PM]] [('Variable:0', []),
 ('Variable_1:0', []),
 ('Variable_2:0', []),
 ('style_encoder/bidirectional/lstm_cell/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias:0', [512]),
 ('style_encoder/dense/kernel:0', [256, 1]),
 ('style_encoder/dense/bias:0', [1]),
 ('style_encoder/dense_1/kernel:0', [256, 256]),
 ('style_encoder/dense_1/bias:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel:0', [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights:0', [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias:0', [1600]),
 ('rnn_style/gmm/weights:0', [400, 121]),
 ('rnn_style/gmm/biases:0', [121]),
 ('style_encoder/bidirectional/lstm_cell/kernel/RMSProp:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/kernel/RMSProp_1:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel/RMSProp:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel/RMSProp_1:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias/RMSProp:0', [512]),
 ('style_encoder/bidirectional/lstm_cell/bias/RMSProp_1:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel/RMSProp:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel/RMSProp_1:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel/RMSProp:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel/RMSProp_1:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias/RMSProp:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias/RMSProp_1:0', [512]),
 ('style_encoder/dense/kernel/RMSProp:0', [256, 1]),
 ('style_encoder/dense/kernel/RMSProp_1:0', [256, 1]),
 ('style_encoder/dense/bias/RMSProp:0', [1]),
 ('style_encoder/dense/bias/RMSProp_1:0', [1]),
 ('style_encoder/dense_1/kernel/RMSProp:0', [256, 256]),
 ('style_encoder/dense_1/kernel/RMSProp_1:0', [256, 256]),
 ('style_encoder/dense_1/bias/RMSProp:0', [256]),
 ('style_encoder/dense_1/bias/RMSProp_1:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel/RMSProp:0',
  [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel/RMSProp_1:0',
  [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias/RMSProp:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights/RMSProp:0',
  [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights/RMSProp_1:0',
  [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases/RMSProp:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases/RMSProp_1:0',
  [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel/RMSProp:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel/RMSProp_1:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias/RMSProp:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel/RMSProp:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel/RMSProp_1:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias/RMSProp:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/gmm/weights/RMSProp:0', [400, 121]),
 ('rnn_style/gmm/weights/RMSProp_1:0', [400, 121]),
 ('rnn_style/gmm/biases/RMSProp:0', [121]),
 ('rnn_style/gmm/biases/RMSProp_1:0', [121])]
[[05/07/2025 09:56:59 PM]] trainable parameters:
[[05/07/2025 09:56:59 PM]] [('style_encoder/bidirectional/lstm_cell/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias:0', [512]),
 ('style_encoder/dense/kernel:0', [256, 1]),
 ('style_encoder/dense/bias:0', [1]),
 ('style_encoder/dense_1/kernel:0', [256, 256]),
 ('style_encoder/dense_1/bias:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel:0', [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights:0', [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias:0', [1600]),
 ('rnn_style/gmm/weights:0', [400, 121]),
 ('rnn_style/gmm/biases:0', [121])]
[[05/07/2025 09:56:59 PM]] trainable parameter count:
[[05/07/2025 09:56:59 PM]] 5070128
[[05/07/2025 09:56:59 PM]] built graph
[[05/07/2025 09:56:59 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:56:59 PM]] all parameters:
[[05/07/2025 09:56:59 PM]] [('Variable:0', []),
 ('Variable_1:0', []),
 ('Variable_2:0', []),
 ('style_encoder/bidirectional/lstm_cell/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias:0', [512]),
 ('style_encoder/dense/kernel:0', [256, 1]),
 ('style_encoder/dense/bias:0', [1]),
 ('style_encoder/dense_1/kernel:0', [256, 256]),
 ('style_encoder/dense_1/bias:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel:0', [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights:0', [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias:0', [1600]),
 ('rnn_style/gmm/weights:0', [400, 121]),
 ('rnn_style/gmm/biases:0', [121]),
 ('style_encoder/bidirectional/lstm_cell/kernel/RMSProp:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/kernel/RMSProp_1:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel/RMSProp:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel/RMSProp_1:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias/RMSProp:0', [512]),
 ('style_encoder/bidirectional/lstm_cell/bias/RMSProp_1:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel/RMSProp:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel/RMSProp_1:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel/RMSProp:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel/RMSProp_1:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias/RMSProp:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias/RMSProp_1:0', [512]),
 ('style_encoder/dense/kernel/RMSProp:0', [256, 1]),
 ('style_encoder/dense/kernel/RMSProp_1:0', [256, 1]),
 ('style_encoder/dense/bias/RMSProp:0', [1]),
 ('style_encoder/dense/bias/RMSProp_1:0', [1]),
 ('style_encoder/dense_1/kernel/RMSProp:0', [256, 256]),
 ('style_encoder/dense_1/kernel/RMSProp_1:0', [256, 256]),
 ('style_encoder/dense_1/bias/RMSProp:0', [256]),
 ('style_encoder/dense_1/bias/RMSProp_1:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel/RMSProp:0',
  [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel/RMSProp_1:0',
  [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias/RMSProp:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights/RMSProp:0',
  [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights/RMSProp_1:0',
  [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases/RMSProp:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases/RMSProp_1:0',
  [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel/RMSProp:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel/RMSProp_1:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias/RMSProp:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel/RMSProp:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel/RMSProp_1:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias/RMSProp:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/gmm/weights/RMSProp:0', [400, 121]),
 ('rnn_style/gmm/weights/RMSProp_1:0', [400, 121]),
 ('rnn_style/gmm/biases/RMSProp:0', [121]),
 ('rnn_style/gmm/biases/RMSProp_1:0', [121])]
[[05/07/2025 09:56:59 PM]] trainable parameters:
[[05/07/2025 09:56:59 PM]] [('style_encoder/bidirectional/lstm_cell/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias:0', [512]),
 ('style_encoder/dense/kernel:0', [256, 1]),
 ('style_encoder/dense/bias:0', [1]),
 ('style_encoder/dense_1/kernel:0', [256, 256]),
 ('style_encoder/dense_1/bias:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel:0', [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights:0', [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias:0', [1600]),
 ('rnn_style/gmm/weights:0', [400, 121]),
 ('rnn_style/gmm/biases:0', [121])]
[[05/07/2025 09:56:59 PM]] trainable parameter count:
[[05/07/2025 09:56:59 PM]] 5070128
[[05/07/2025 09:56:59 PM]] built graph
[[05/07/2025 09:56:59 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:56:59 PM]] all parameters:
[[05/07/2025 09:56:59 PM]] [('Variable:0', []),
 ('Variable_1:0', []),
 ('Variable_2:0', []),
 ('style_encoder/bidirectional/lstm_cell/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias:0', [512]),
 ('style_encoder/dense/kernel:0', [256, 1]),
 ('style_encoder/dense/bias:0', [1]),
 ('style_encoder/dense_1/kernel:0', [256, 256]),
 ('style_encoder/dense_1/bias:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel:0', [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights:0', [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias:0', [1600]),
 ('rnn_style/gmm/weights:0', [400, 121]),
 ('rnn_style/gmm/biases:0', [121]),
 ('style_encoder/bidirectional/lstm_cell/kernel/RMSProp:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/kernel/RMSProp_1:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel/RMSProp:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel/RMSProp_1:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias/RMSProp:0', [512]),
 ('style_encoder/bidirectional/lstm_cell/bias/RMSProp_1:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel/RMSProp:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel/RMSProp_1:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel/RMSProp:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel/RMSProp_1:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias/RMSProp:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias/RMSProp_1:0', [512]),
 ('style_encoder/dense/kernel/RMSProp:0', [256, 1]),
 ('style_encoder/dense/kernel/RMSProp_1:0', [256, 1]),
 ('style_encoder/dense/bias/RMSProp:0', [1]),
 ('style_encoder/dense/bias/RMSProp_1:0', [1]),
 ('style_encoder/dense_1/kernel/RMSProp:0', [256, 256]),
 ('style_encoder/dense_1/kernel/RMSProp_1:0', [256, 256]),
 ('style_encoder/dense_1/bias/RMSProp:0', [256]),
 ('style_encoder/dense_1/bias/RMSProp_1:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel/RMSProp:0',
  [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel/RMSProp_1:0',
  [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias/RMSProp:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights/RMSProp:0',
  [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights/RMSProp_1:0',
  [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases/RMSProp:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases/RMSProp_1:0',
  [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel/RMSProp:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel/RMSProp_1:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias/RMSProp:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel/RMSProp:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel/RMSProp_1:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias/RMSProp:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/gmm/weights/RMSProp:0', [400, 121]),
 ('rnn_style/gmm/weights/RMSProp_1:0', [400, 121]),
 ('rnn_style/gmm/biases/RMSProp:0', [121]),
 ('rnn_style/gmm/biases/RMSProp_1:0', [121])]
[[05/07/2025 09:56:59 PM]] trainable parameters:
[[05/07/2025 09:56:59 PM]] [('style_encoder/bidirectional/lstm_cell/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias:0', [512]),
 ('style_encoder/dense/kernel:0', [256, 1]),
 ('style_encoder/dense/bias:0', [1]),
 ('style_encoder/dense_1/kernel:0', [256, 256]),
 ('style_encoder/dense_1/bias:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel:0', [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights:0', [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias:0', [1600]),
 ('rnn_style/gmm/weights:0', [400, 121]),
 ('rnn_style/gmm/biases:0', [121])]
[[05/07/2025 09:56:59 PM]] trainable parameter count:
[[05/07/2025 09:56:59 PM]] 5070128
[[05/07/2025 09:57:00 PM]] built graph
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] all parameters:
[[05/07/2025 09:57:00 PM]] [('Variable:0', []),
 ('Variable_1:0', []),
 ('Variable_2:0', []),
 ('style_encoder/bidirectional/lstm_cell/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias:0', [512]),
 ('style_encoder/dense/kernel:0', [256, 1]),
 ('style_encoder/dense/bias:0', [1]),
 ('style_encoder/dense_1/kernel:0', [256, 256]),
 ('style_encoder/dense_1/bias:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel:0', [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights:0', [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias:0', [1600]),
 ('rnn_style/gmm/weights:0', [400, 121]),
 ('rnn_style/gmm/biases:0', [121]),
 ('style_encoder/bidirectional/lstm_cell/kernel/RMSProp:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/kernel/RMSProp_1:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel/RMSProp:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel/RMSProp_1:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias/RMSProp:0', [512]),
 ('style_encoder/bidirectional/lstm_cell/bias/RMSProp_1:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel/RMSProp:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel/RMSProp_1:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel/RMSProp:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel/RMSProp_1:0',
  [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias/RMSProp:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias/RMSProp_1:0', [512]),
 ('style_encoder/dense/kernel/RMSProp:0', [256, 1]),
 ('style_encoder/dense/kernel/RMSProp_1:0', [256, 1]),
 ('style_encoder/dense/bias/RMSProp:0', [1]),
 ('style_encoder/dense/bias/RMSProp_1:0', [1]),
 ('style_encoder/dense_1/kernel/RMSProp:0', [256, 256]),
 ('style_encoder/dense_1/kernel/RMSProp_1:0', [256, 256]),
 ('style_encoder/dense_1/bias/RMSProp:0', [256]),
 ('style_encoder/dense_1/bias/RMSProp_1:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel/RMSProp:0',
  [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel/RMSProp_1:0',
  [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias/RMSProp:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights/RMSProp:0',
  [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights/RMSProp_1:0',
  [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases/RMSProp:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases/RMSProp_1:0',
  [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel/RMSProp:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel/RMSProp_1:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias/RMSProp:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel/RMSProp:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel/RMSProp_1:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias/RMSProp:0',
  [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias/RMSProp_1:0',
  [1600]),
 ('rnn_style/gmm/weights/RMSProp:0', [400, 121]),
 ('rnn_style/gmm/weights/RMSProp_1:0', [400, 121]),
 ('rnn_style/gmm/biases/RMSProp:0', [121]),
 ('rnn_style/gmm/biases/RMSProp_1:0', [121])]
[[05/07/2025 09:57:00 PM]] trainable parameters:
[[05/07/2025 09:57:00 PM]] [('style_encoder/bidirectional/lstm_cell/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell/bias:0', [512]),
 ('style_encoder/bidirectional/lstm_cell_1/kernel:0', [3, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/recurrent_kernel:0', [128, 512]),
 ('style_encoder/bidirectional/lstm_cell_1/bias:0', [512]),
 ('style_encoder/dense/kernel:0', [256, 1]),
 ('style_encoder/dense/bias:0', [1]),
 ('style_encoder/dense_1/kernel:0', [256, 256]),
 ('style_encoder/dense_1/bias:0', [256]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/kernel:0', [732, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/weights:0', [732, 30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/attention/biases:0', [30]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_1/bias:0', [1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/kernel:0',
  [1132, 1600]),
 ('rnn_style/StyleAdaptiveLSTMAttentionCell/lstm_cell_2/bias:0', [1600]),
 ('rnn_style/gmm/weights:0', [400, 121]),
 ('rnn_style/gmm/biases:0', [121])]
[[05/07/2025 09:57:00 PM]] trainable parameter count:
[[05/07/2025 09:57:00 PM]] 5070128
[[05/07/2025 09:57:00 PM]] built graph
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Processing failed for item 0: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Processing failed for item 4: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Processing failed for item 5: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Processing failed for item 6: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Processing failed for item 7: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Processing failed for item 8: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Processing failed for item 9: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Processing failed for item 10: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Processing failed for item 11: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Processing failed for item 12: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Processing failed for item 13: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Processing failed for item 14: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Processing failed for item 15: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Processing failed for item 2: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:00 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:00 PM]] Processing failed for item 3: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:01 PM]] Restoring parameters from final_checkpoints/model-10350
[[05/07/2025 09:57:01 PM]] Processing failed for item 1: The Session graph is empty.  Add operations to the graph before calling run().
[[05/07/2025 09:57:20 PM]] Shutting down
[[05/07/2025 09:57:20 PM]] Waiting for application shutdown.
[[05/07/2025 09:57:20 PM]] Application shutdown complete.
[[05/07/2025 09:57:20 PM]] Finished server process [7]
